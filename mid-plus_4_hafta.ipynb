{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXyrGbX3RDbq"
      },
      "source": [
        "# âœ¨ YAPAY ZEKA TOPLULUÄU | YAPAY ZEKA GELÄ°ÅÄ°M KAMPI\n",
        "## ğŸ–ï¸ MIDDLE PLUS HAFTA 4 | *Fine-Tuning - Parametre Verimli Fine-Tuning - LoRA*\n",
        "### 4. Haftaya giriÅŸ : Bu haftanÄ±n amacÄ±, bÃ¼yÃ¼k dil modellerini belli gÃ¶revlere veya belirli alanlara uyarlamakta kullanÄ±lan \"Fine-Tuning\" ve \"parametre verimli fine-tuning (PEFT)\" kavramlarÄ±nÄ± ve Ã¶zellikle LoRA tekniÄŸini kavramsal ve uygulama dÃ¼zeyinde tanÄ±manÄ±zÄ± saÄŸlamaktÄ±r."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-Tuning Nedir?\n",
        "LLM, Fine-Tuning, bÃ¼yÃ¼k bir veriyle GENEL AMAÃ‡LI Ã¼retilmiÅŸ bir dil modelini belirli bir hedefe Ã¶zel hale getirmektir sÃ¼recidir. Daha kÃ¼Ã§Ã¼k fakat gÃ¶rev odaklÄ± bir veri setiyle yeniden eÄŸitim yapÄ±lÄ±r. Yani modelin \"her konuda idare eder\" ÅŸeklindeki genel zekasÄ±nÄ± alÄ±p, onu tek bir alanda Ã§ok daha tutarlÄ± ve gÃ¼venilir bir uzman gibi davranacak noktaya Ã§ekmekte kullanÄ±lÄ±r. \n",
        "\n",
        "Fine Tuning'e ihtiyaÃ§ duyulmasÄ±nÄ±n temel sebebi, bÃ¼yÃ¼k dil modelleri kullanÄ±rken yanÄ±tlarÄ± etkileyen en bÃ¼yÃ¼k etken = promptlardÄ±r. Fakat LLM'ler devamlÄ± olarak aynÄ± baÅŸarÄ±yÄ± veya istikrarÄ± saÄŸlayamamaktadÄ±r. Belli tonun korunmasÄ± gereken, belirli bir cevap ÅŸablonuna sadakat, alan terimlerinin uygun kullanÄ±mÄ± gibi gereksinimler, fine-tuning'i pratik bir Ã§Ã¶zÃ¼m haline getirmektedir. Fine-Tuning ile performans standardize edilip, Ã§Ä±ktÄ± kalitesi arttÄ±rÄ±lmasÄ± hedeflenmektedir. \n",
        "\n",
        "MÃ¼ÅŸteri destek botlarÄ±, iade-kargo sÃ¼reÃ§leri gibi alanlarda daha kÄ±sa ve isabetli mesajlar Ã¼retmeyi kolaylaÅŸtÄ±rÄ±r. Hukuk, tÄ±p, finans gibi daha teknik olan ve uzmanlÄ±k gerektiren alanlarda da sÄ±klÄ±kla uygulanmaktadÄ±r.\n",
        "\n",
        "Teknik sÃ¼reÃ§, uygun bir temel model seÃ§imiyle baÅŸlar. ArdÄ±ndan hedef gÃ¶reve uygun \"instruction-response\" veya \"input-out\" biÃ§imde veriler hazÄ±rlanÄ±r ve tokenize edilir. EÄŸitim aÅŸamasÄ±nda ya tÃ¼m model aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellenir (full fine-tuning) ya da daha verimli seÃ§enek olan modelin bÃ¼yÃ¼k bir kÄ±smÄ± serbest bÄ±rakÄ±lÄ±p yalnÄ±zca bazÄ± katmanlar eÄŸitilir (PEFT/LoRA). EÄŸitim; modelin hedef yanÄ±tlarÄ± seÃ§ilen alana daha doÄŸru yanÄ±tlar Ã¼retmesini saÄŸlayÄ±p, kayÄ±plarÄ±n minimize edilmesi prensibine dayanmaktadÄ±r.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdQPE1g8SM2L"
      },
      "source": [
        "# Parametre Verimli Fine-Tuning (PEFT): \n",
        "PEFT (Paramtre-Efficient Fine-Tuning), bÃ¼yÃ¼k dil modellerini belirli bir gÃ¶reve uyarlarken tÃ¼m model parametrelerini gÃ¼ncellemek yerine ,fine-tuning'de bu ÅŸekilde yapÄ±lÄ±yordu, yalnÄ±zca Ã§ok kÃ¼Ã§Ã¼k ek parametre setini eÄŸtimeyi hedefleyen yÃ¶ntemdir. Bu yaklaÅŸÄ±m fine-tuning amacÄ±nÄ± korurken bunu Ã‡OK daha dÃ¼ÅŸÃ¼k maliyet ve daha yÃ¼ksek pratiklik iel yapmayÄ± hedeflemektedir.\n",
        "\n",
        "Klasik (full) fine-tuning ile temel fark, Ã¶ÄŸrenilen parametre miktarÄ± ve bunun doÄŸurduÄŸu maliyet Ã¼zerindedir. KullanÄ±ldÄ±klarÄ± alanlar Ã§oÄŸunlukla aynÄ±dÄ±r. SonuÃ§ olarak PEFT, fine-tuningâ€™in adaptasyon gÃ¼cÃ¼nÃ¼ koruyup, maliyet ve karmaÅŸÄ±klÄ±ÄŸÄ± bÃ¼yÃ¼k Ã¶lÃ§Ã¼de dÃ¼ÅŸÃ¼ren daha pratik ve modern bir yaklaÅŸÄ±m olarak bilinir.\n",
        "\n",
        "## LoRA (Low-Rank Adaptation): \n",
        "\n",
        "LoRA, PEFT tekniklerinden birisidir. Son derece hafif ve modÃ¼ler bir yapÄ±sÄ± bulunmaktadÄ±r. \n",
        "\n",
        "LoRAâ€™nÄ±n temel fikri, modelin Ã¶zellikle dikkat (attention) mekanizmalarÄ±nda yer alan bÃ¼yÃ¼k aÄŸÄ±rlÄ±k matrislerine yapÄ±lacak gÃ¼ncellemeleri doÄŸrudan Ã¶ÄŸrenmek yerine, bu gÃ¼ncellemeyi dÃ¼ÅŸÃ¼k-rank bir temsil ile ifade etmektir. BaÅŸka bir deyiÅŸle, bÃ¼yÃ¼k bir gÃ¼ncelleme matrisi yerine, iki kÃ¼Ã§Ã¼k matrisin Ã§arpÄ±mÄ±yla aynÄ± etkiyi Ã¼retebilecek bir yapÄ± Ã¶ÄŸrenilir.\n",
        "\n",
        "LoRAâ€™nÄ±n pratik deÄŸeri, aynÄ± temel model Ã¼zerinde farklÄ± amaÃ§lara yÃ¶nelik ayrÄ± LoRA paketleri oluÅŸturulabilmesinde de ortaya Ã§Ä±kar. BÃ¶ylece tek bir base model, farklÄ± kullanÄ±m senaryolarÄ±nda farklÄ± LoRA bileÅŸenleriyle Ã§alÄ±ÅŸtÄ±rÄ±labilir. Bu yaklaÅŸÄ±m, Ã¶zellikle Ã¼rÃ¼nleÅŸtirme sÃ¼reÃ§lerinde sÃ¼rÃ¼mleme ve bakÄ±m aÃ§Ä±sÄ±ndan dÃ¼zenli bir yapÄ± sunar.\n",
        "\n",
        "KÄ±saca LoRA, bÃ¼yÃ¼k modellere hedefe yÃ¶nelik davranÄ±ÅŸ eklemeyi basit, modÃ¼ler ve teknik olarak ÅŸÄ±k bir gÃ¼ncelleme temsiliyle mÃ¼mkÃ¼n kÄ±lan bir yÃ¶ntemdir. Modelin genel gÃ¼cÃ¼nÃ¼ korurken, belirli bir gÃ¶revde tutarlÄ±lÄ±k ve performans artÄ±ÅŸÄ± saÄŸlamayÄ± hedefleyen pratik bir ince ayar stratejisi olarak konumlanÄ±r.\n",
        "\n",
        "\n",
        "# HuggingFace PEFT KÃ¼tÃ¼phanesi :\n",
        "HuggingFace PEFT kÃ¼tÃ¼phanesi, parametre verimli fine-tuning fikrini uygulamada dÃ¼zenli ve tekrarlanabilir bir iÅŸ akÄ±ÅŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in tasarlanmÄ±ÅŸ bir araÃ§ setidir. Bu kÃ¼tÃ¼phane sayesinde bir base modeli alÄ±p LoRA gibi yÃ¶ntemleri standart bir API ile modele entegre edebilir, eÄŸitim kapsamÄ±nÄ± yalnÄ±zca hedeflenen kÃ¼Ã§Ã¼k parametre bloklarÄ±yla sÄ±nÄ±rlayabilirsiniz.\n",
        "\n",
        "Pratikte PEFT, <br>\n",
        "â†’konfigÃ¼rasyon tanÄ±mla <br>\n",
        "â†’ modeli PEFT biÃ§iminde sar <br>\n",
        "â†’ eÄŸitimde yalnÄ±zca ilgili bileÅŸenleri gÃ¼ncelle <br>\n",
        "â†’ adapter olarak kaydet <br>\n",
        "â†’ gerektiÄŸinde base model Ã¼zerine tekrar yÃ¼kle <br>\n",
        "akÄ±ÅŸÄ±nÄ± netleÅŸtirir. Bu, hem eÄŸitim tarafÄ±nda hangi parametrelerin gerÃ§ekten gÃ¼ncellendiÄŸinin tespitini kolaylaÅŸtÄ±rÄ±r hem de proje yÃ¶netiminde Ã§Ä±ktÄ±larÄ± daha kÃ¼Ã§Ã¼k ve taÅŸÄ±nabilir hale getirir.\n",
        "\n",
        "Bu kÃ¼tÃ¼phanenin asÄ±l katkÄ±sÄ±, LoRAâ€™nÄ±n doÄŸru ÅŸekilde uygulanmasÄ±nÄ± ve aÄŸÄ±r model gÃ¼ncellemesi yerine adapter temelli yÃ¶netimi kolaylaÅŸtÄ±rmasÄ±dÄ±r. BÃ¶ylece aynÄ± temel model Ã¼zerinde farklÄ± gÃ¶revler veya farklÄ± Ã¼slup hedefleri iÃ§in ayrÄ± adapterâ€™lar Ã¼retmek ve bunlarÄ± kontrollÃ¼ biÃ§imde test etmek daha temiz bir yÃ¶nteme dÃ¶nÃ¼ÅŸÃ¼r. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxy35geSUgr"
      },
      "source": [
        "DokÃ¼mantasyon / pratik\n",
        "- https://huggingface.co/docs/peft/en/index\n",
        "- https://arxiv.org/abs/1706.03762\n",
        "- https://arxiv.org/abs/1902.00751\n",
        "- https://arxiv.org/abs/2106.09685\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Okuma KÃ¶ÅŸesi\n",
        "\n",
        "RAG Nedir? (Retrieval-Augmented Generation) : \n",
        "\n",
        "Fine-Tuning ve LoRA ile bir modelin \"nasÄ±l\" konuÅŸmasÄ± gerektiÄŸini, hangi formatta Ã§Ä±ktÄ± Ã¼reteceÄŸini veya belirli bir alanÄ±n (tÄ±p, hukuk) jargonunu nasÄ±l kullanacaÄŸÄ±nÄ± modele kalÄ±cÄ± olarak Ã¶ÄŸrettik diyelim. Ancak modelin \"ne bildiÄŸi\" hala eÄŸitim verisiyle sÄ±nÄ±rlÄ±dÄ±r. Bir yapay zekaya, eÄŸitim setinde olmayan gÃ¼ncel bir bilgiyi (Ã¶rneÄŸin dÃ¼nkÃ¼ dÃ¶viz kuru veya ÅŸirketinize ait Ã¶zel PDF dosyalarÄ±) Ã¶ÄŸretmek iÃ§in her gÃ¼n fine-tuning yapmak imkansÄ±z ve maliyetlidir.\n",
        "\n",
        "Ä°ÅŸte bu noktada RAG (Retrieval-Augmented Generation) devreye girer. RAG, modelin parametrelerini deÄŸiÅŸtirmek yerine, modelin cevap vermeden Ã¶nce gÃ¼venilir bir dÄ±ÅŸ kaynaÄŸa (VektÃ¶r VeritabanlarÄ±) bakÄ±p kopya Ã§ekmesini saÄŸlayan mimaridir. Fine-Tuning modelin davranÄ±ÅŸÄ±nÄ± ve yeteneÄŸini kalÄ±cÄ± hale getirirken, RAG modelin bilgisini dinamik ve gÃ¼ncel tutar. Modern LLM uygulamalarÄ±nda genellikle en iyi sonuÃ§; sektÃ¶rel dili Ã¶ÄŸrenmesi iÃ§in Fine-Tuning yapÄ±lmÄ±ÅŸ bir modelin, gÃ¼ncel veriye eriÅŸmesi iÃ§in RAG mimarisiyle desteklendiÄŸi hibrit yapÄ±lardan alÄ±nÄ±r."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YardÄ±mcÄ± Kaynaklar\n",
        "- 1 : https://youtu.be/t1caDsMzWBk?si=kT051w0MOIuWnqqW - LoRA & QLoRA Fine-tuning Explained In-Depth\n",
        "- 2 : https://www.youtube.com/watch?v=0XPZlR3_GgI - Fine-Tuning Llama 3 on a Custom Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š Ã–dev 1: Senaryo BazlÄ± Mimari TasarÄ±mÄ± (Fine-Tuning vs. RAG)\n",
        "\n",
        "**Senaryo:** Bir \"Finansal DanÄ±ÅŸman AsistanÄ±\" geliÅŸtirdiÄŸinizi hayal edin. Bu asistanÄ±n hem finansal terimleri (Ã¶rneÄŸin; \"kÄ±sa pozisyon\", \"likidite tuzaÄŸÄ±\") doÄŸru bir jargonla kullanmasÄ± hem de **anlÄ±k** borsa verilerine gÃ¶re (Ã¶rneÄŸin; \"bugÃ¼nkÃ¼ X hissesinin deÄŸeri\") yorum yapmasÄ± gerekiyor.\n",
        "\n",
        "AÅŸaÄŸÄ±daki sorularÄ± bu senaryoya gÃ¶re yanÄ±tlayÄ±nÄ±z:\n",
        "\n",
        "1.  **Fine-Tuning KullanÄ±mÄ±:** Bu projede Fine-Tuning (veya LoRA) teknolojisini hangi amaÃ§la kullanÄ±rsÄ±nÄ±z? Modele neyi Ã¶ÄŸretmeyi hedeflersiniz?\n",
        "2.  **RAG KullanÄ±mÄ±:** RAG (Retrieval-Augmented Generation) teknolojisini hangi amaÃ§la kullanÄ±rsÄ±nÄ±z? Hangi veriler buradan gelmelidir?\n",
        "3.  **Neden Ä°kisi Birlikte?** Neden sadece Fine-Tuning yapmak bu proje iÃ§in yeterli ve maliyet etkin olmazdÄ±? (DokÃ¼mandaki \"bilgi vs. davranÄ±ÅŸ\" ayrÄ±mÄ±na dikkat ederek aÃ§Ä±klayÄ±nÄ±z)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š Ã–dev 2: Ã–dev dÃ¶kÃ¼manÄ±nda bulunan gÃ¶rev kodlarÄ±nÄ± yazmak ve teslim etmek.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
