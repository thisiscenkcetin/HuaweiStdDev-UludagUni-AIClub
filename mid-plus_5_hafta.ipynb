{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f37de4",
   "metadata": {
    "id": "d7f37de4"
   },
   "source": [
    "# âœ¨ YAPAY ZEKA TOPLULUÄU | YAPAY ZEKA GELÄ°ÅÄ°M KAMPI\n",
    "## ğŸ–ï¸ MIDDLE PLUS HAFTA 5 | *Prompt Engineering - RAG*\n",
    "### 5. Haftaya giriÅŸ : Bu haftanÄ±n amacÄ±, bÃ¼yÃ¼k dil modellerinden daha tutarlÄ± ve kontrol edilebilir Ã§Ä±ktÄ±lar almayÄ± saÄŸlayan â€œprompt engineeringâ€ yaklaÅŸÄ±mÄ±nÄ± oturtmak ve bilgi eksikliÄŸini dÄ±ÅŸ kaynaklarla tamamlayan RAG (Retrieval-Augmented Generation) mantÄ±ÄŸÄ±nÄ± uygulama dÃ¼zeyinde anlamanÄ±zÄ± saÄŸlamaktÄ±r. Fine-Tuning bir modelin â€œnasÄ±l konuÅŸacaÄŸÄ±nÄ±â€ kalÄ±cÄ± biÃ§imde ÅŸekillendirirken, prompt engineering aynÄ± modeli anlÄ±k olarak doÄŸru yÃ¶nlendirmeyi; RAG ise modele eÄŸitiminde olmayan gÃ¼ncel/kurumsal bilgiyi gÃ¼venilir bir kaynaktan getirip cevap Ã¼retimine dahil etmeyi hedefler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4956d8",
   "metadata": {
    "id": "7b4956d8"
   },
   "source": [
    "# âœ¨ YAPAY ZEKA TOPLULUÄU | YAPAY ZEKA GELÄ°ÅÄ°M KAMPI\n",
    "## ğŸ–ï¸ MIDDLE PLUS HAFTA 5 | *Prompt Engineering - RAG*\n",
    "### 5. Haftaya giriÅŸ : Bu haftanÄ±n amacÄ±, bÃ¼yÃ¼k dil modellerinden daha tutarlÄ± ve kontrol edilebilir Ã§Ä±ktÄ±lar almayÄ± saÄŸlayan â€œprompt engineeringâ€ yaklaÅŸÄ±mÄ±nÄ± oturtmak ve bilgi eksikliÄŸini dÄ±ÅŸ kaynaklarla tamamlayan RAG (Retrieval-Augmented Generation) mantÄ±ÄŸÄ±nÄ± uygulama dÃ¼zeyinde anlamanÄ±zÄ± saÄŸlamaktÄ±r. Fine-Tuning bir modelin â€œnasÄ±l konuÅŸacaÄŸÄ±nÄ±â€ kalÄ±cÄ± biÃ§imde ÅŸekillendirirken, prompt engineering aynÄ± modeli anlÄ±k olarak doÄŸru yÃ¶nlendirmeyi; RAG ise modele eÄŸitiminde olmayan gÃ¼ncel/kurumsal bilgiyi gÃ¼venilir bir kaynaktan getirip cevap Ã¼retimine dahil etmeyi hedefler.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Prompt Engineering Nedir?\n",
    "Prompt engineering, bir LLMâ€™e yalnÄ±zca â€œneâ€ sorulduÄŸunu deÄŸil;\n",
    "* hangi rol ile,\n",
    "* hangi konuda, \n",
    "* hangi kÄ±sÄ±tlamalar ile, \n",
    "* hangi formatta \n",
    "\n",
    "cevap vermesi gerektiÄŸini net ÅŸekilde tanÄ±mlama sÃ¼recidir. Ã‡oÄŸu senaryoda modelin kalitesi kadar, modelin Ã¶nÃ¼ne koyduÄŸun gÃ¶rev tanÄ±mÄ± da sonucu belirler. Ã‡Ä±ktÄ±nÄ±n hedefi, sÄ±nÄ±rlarÄ± ve tonu Ã¶nceden belirlenirse model Ã§ok daha stabil Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Prompt TÃ¼rleri: zero-shot, few-shot, reasoning odaklÄ± promptlar\n",
    " ---> https://youtu.be/sZIV7em3JA8?si=GBspqG1jibuyPwlS\n",
    "\n",
    "* Zero-shot prompting:\n",
    "modele Ã¶rnek vermeden gÃ¶rev tanÄ±mÄ± yapmaktÄ±r; hÄ±zlÄ±dÄ±r ama belirsizlik varsa sapma payÄ± artar. \n",
    "* One-shot / few-shot prompting:\n",
    "ise modele bir veya birkaÃ§ Ã¶rnek gÃ¶stererek beklenen deseni â€œtaklit etmesiniâ€ saÄŸlar. Ã–zellikle format standardizasyonu (JSON ÅŸemasÄ± ) iÃ§in Ã§ok etkilidir. \n",
    "* Reasoning (akÄ±l yÃ¼rÃ¼tme) odaklÄ± :\n",
    "Bu promptlar ise modelden tek hamlede cevap yerine, Ã¶nce kÄ±sa bir plan/ara adÄ±mlar Ã§Ä±karÄ±p sonra sonuca gitmesini ister; bu yaklaÅŸÄ±m karmaÅŸÄ±k problemlerde doÄŸruluÄŸu artÄ±rabilir, fakat gereksiz uzun Ã§Ä±ktÄ±larÄ± engellemek iÃ§in ara aÃ§Ä±klamalarÄ± â€œkÄ±sa ve Ã¶zâ€ sÄ±nÄ±rlamak Ã§oÄŸu zaman daha iyi sonuÃ§ verir.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Prompt optimizasyonu\n",
    "Prompt optimizasyonu, â€œtek seferde mÃ¼kemmel prompt yazmakâ€ deÄŸil; hedefe gÃ¶re tekrar tekrar iyileÅŸtirme yapmaktÄ±r. Genelde sÃ¼reÃ§ ÅŸu ÅŸekilde ilerler:\n",
    "1. GÃ¶revi Ã¶lÃ§Ã¼lebilir hale getir -> beklenen format, doÄŸruluk ÅŸartÄ±, kapsam dÄ±ÅŸÄ± alanlar gibi \n",
    "2. modele gerekli baÄŸlamÄ± ver -> tanÄ±mlar, kurallar, Ã¶rnekler, veri parÃ§alarÄ± vs.\n",
    "3. Ã§Ä±ktÄ±yÄ± kÄ±sÄ±tlarla kontrol et -> uzunluk limiti, dil/ton, madde sayÄ±sÄ± ve kaynak gÃ¶sterme \n",
    "4. kÃ¼Ã§Ã¼k bir test setiyle dene ve hatalarÄ±n tÃ¼rÃ¼ne gÃ¶re promptu gÃ¼ncelle\n",
    "\n",
    "En yaygÄ±n hatalar; belirsiz istek yani modelin kendi kendine yorumlamasÄ±, Ã§eliÅŸen kurallar, gereksiz geniÅŸ konu sÄ±nÄ±rlamasÄ±, eksik format tanÄ±mÄ± ve prompt injection gibi kÃ¶tÃ¼ niyetli metinlerin kurallarÄ± delmeye Ã§alÄ±ÅŸmasÄ±dÄ±r.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Etkili prompt yazabilme (Pratik yaklaÅŸÄ±m)\n",
    "Etkili prompt yazmak, modele bir soru sormaktan Ã§ok, onu kÃ¼Ã§Ã¼k bir gÃ¶rev tanÄ±mÄ±yla doÄŸru ÅŸekilde yÃ¶nlendirmektir. Bu yÃ¼zden iyi bir prompt genelde 4 parÃ§adan oluÅŸur:\n",
    "1. **AmaÃ§**: Tam olarak ne Ã¼retilecek?\n",
    "2. **BaÄŸlam** modelin bilmesi gereken minimum bilgi \n",
    "3. **KÄ±sÄ±tlar** Neleri yapmamalÄ± / Hangi formatta Ã¼retmeli \n",
    "4. **DeÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼** BaÅŸarÄ±lÄ± cevap nasÄ±l anlaÅŸÄ±lÄ±r?. \n",
    "Bu yapÄ±, modelin yorum alanÄ±nÄ± daraltÄ±r ve Ã§Ä±ktÄ±yÄ± daha tutarlÄ± hale getirir.\n",
    "\n",
    "### Prompt ÅŸablonu (kopyalaâ€“yapÄ±ÅŸtÄ±r)\n",
    "* **Rol:** â€¦  \n",
    "* **GÃ¶rev:** â€¦  \n",
    "* **Girdi:** â€¦  \n",
    "* **Kurallar:** â€¦ KÄ±sa ve madde madde  \n",
    "* **Ã‡Ä±ktÄ± formatÄ±:** â€¦  \n",
    "* **Kalite kontrol:** â€¦ \"Emin deÄŸilsen belirt\" demek gibi\n",
    "\n",
    "### Mini Ã¶rnek\n",
    "* **Rol:** KÄ±demli bir asistan Ã¶ÄŸretmen gibi davran.  \n",
    "* **GÃ¶rev:** AÅŸaÄŸÄ±daki metni 6 maddede Ã¶zetle.  \n",
    "* **Girdi:** (metin)  \n",
    "* **Kurallar:** <br>    - Teknik terimleri koru, aÃ§Ä±klama ekleme  <br>      -VarsayÄ±m yapma kaynak dÄ±ÅŸÄ±na Ã§Ä±kma  \n",
    "* **Ã‡Ä±ktÄ± formatÄ±:** Markdown madde listesi  \n",
    "* **Kalite kontrol:** Metinde olmayan bilgi ekleme.\n",
    "\n",
    "Bu yaklaÅŸÄ±mÄ± oturtunca, prompt yazmak â€œÅŸans iÅŸiâ€ olmaktan Ã§Ä±kar; test edilebilir, geliÅŸtirilebilir bir mÃ¼hendislik adÄ±mÄ±na dÃ¶nÃ¼ÅŸÃ¼r.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Retrieval-Augmented Generation (RAG) mantÄ±ÄŸÄ±\n",
    "RAG, modelin parametrelerini deÄŸiÅŸtirmeden ekstradan dÄ±ÅŸ bilgiyle desteklenmesini saÄŸlayan mimaridir. \n",
    "MantÄ±k basittir: \n",
    "1. Kurum iÃ§i PDFâ€™ler, dÃ¶kÃ¼manlar, wiki sayfalarÄ± veya CSV verileri gibi kaynaklar parÃ§alara ayrÄ±lÄ±r (chunking) \n",
    "2. Bu parÃ§alar embedding ile vektÃ¶r uzayÄ±nda temsil edilir ve bir vektÃ¶r veritabanÄ±nda saklanÄ±r\n",
    "3. KullanÄ±cÄ± soru sorduÄŸunda, soru embeddingâ€™e Ã§evrilir ve en benzer parÃ§alar geri getirilir (retrieval)\n",
    "4. Son adÄ±mda LLM, sadece kendi ezberine dayanmak yerine bu getirilen parÃ§alarÄ± baÄŸlam olarak alÄ±r ve cevabÄ± bu kanÄ±ta dayanarak Ã¼retir. \n",
    "Ä°yi bir RAG sistemi; doÄŸru parÃ§a bulma (retrieval kalitesi), doÄŸru parÃ§ayÄ± doÄŸru sÄ±rada sunma ve cevabÄ± kanÄ±ta/kaynaÄŸa baÄŸlÄ± Ã¼retme (halÃ¼sÃ¼nyason azaltma) tarafÄ±nda gÃ¼Ã§lÃ¼ olmalÄ±dÄ±r.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95948c12",
   "metadata": {
    "id": "95948c12"
   },
   "source": [
    "##  LangChain\n",
    "\n",
    "LangChain, LLMâ€™leri diÄŸer sistemlerle entegre etmeyi kolaylaÅŸtÄ±ran bir Python frameworkâ€™Ã¼dÃ¼r.\n",
    "\n",
    "**Temel BileÅŸenler:**\n",
    "\n",
    "- PromptTemplate: Dinamik prompt oluÅŸturur.\n",
    "\n",
    "- LLMChain: Prompt â†’ Model â†’ YanÄ±t zinciri\n",
    "\n",
    "- VectorStore: RAG iÃ§in gerekli bellek yapÄ±sÄ±\n",
    "\n",
    "- Tool, Memory, Agent: GeliÅŸmiÅŸ kullanÄ±m\n",
    "\n",
    "- LangChain, Ã¶zellikle RAG ve agent sistemlerinde tercih edilir.\n",
    "\n",
    "## LlamaIndex\n",
    "* https://youtu.be/xeFHFZpJpxc?si=WY6a3hAoR2-VkY0F (TÃ¼rkÃ§e) <br>\n",
    "\n",
    "\n",
    "LangChain, LLM uygulamalarÄ±nÄ± zincirler halinde kurmayÄ±, prompt ÅŸablonlarÄ±nÄ± yÃ¶netmeyi; retriever/vector store entegrasyonlarÄ±nÄ± ve tasarÄ±mÄ±nÄ± kolaylaÅŸtÄ±ran bir Ã§atÄ± sunar. <br>\n",
    "LlamaIndex ise Ã¶zellikle â€œveriyi indeksleme ve sorgulamaâ€ tarafÄ±nda gÃ¼Ã§lÃ¼dÃ¼r. \n",
    "* FarklÄ± veri kaynaklarÄ±nÄ± (PDF, web, Notion benzeri) alÄ±p dÃ¼zgÃ¼n parÃ§alara ayÄ±rma \n",
    "* Metadata ekleme \n",
    "* Ä°nddeks oluÅŸturma ve sorgu sÄ±rasÄ±nda doÄŸru baÄŸlamÄ± Ã¼retme \n",
    "\n",
    "sÃ¼reÃ§lerine odaklanÄ±r. Pratikte iki yaklaÅŸÄ±m da benzer temel bloklarÄ± kullanÄ±r \n",
    "* loader â†’ splitter â†’ embedding â†’ vector store â†’ retriever â†’ LLM  \n",
    "\n",
    "Hangisini seÃ§eceÄŸinizi genelde projenin ihtiyacÄ± belirler: daha Ã§ok uygulama akÄ±ÅŸÄ± veya entegrasyon mu, yoksa veri indeksleme vee sorgu kalitesi mi aÄŸÄ±r basÄ±yor? SorularÄ±nÄ±n cevaplarÄ±na gÃ¶re belirlenir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14472eaa",
   "metadata": {
    "id": "14472eaa"
   },
   "source": [
    "## LangGraph\n",
    "\n",
    "LangGraph, LangChain Ã¼zerine kurulmuÅŸ bir \"durum makinesi\" (state machine) frameworkâ€™Ã¼dÃ¼r. Bu yapÄ±, birden fazla adÄ±m iÃ§eren, dallanan ve koÅŸula baÄŸlÄ± olarak farklÄ± yollar izleyen LLM uygulamalarÄ±nda akÄ±ÅŸ kontrolÃ¼ saÄŸlamaya yarar.\n",
    "\n",
    "LangGraph ile geliÅŸtirici, bir LLMâ€™in girdiye gÃ¶re izlemesi gereken yolu grafik tabanlÄ± olarak tanÄ±mlar. Bu yollar; dosya yÃ¼klenip yÃ¼klenmediÄŸine, kullanÄ±cÄ±dan gelen komutun tÃ¼rÃ¼ne ya da Ã¶nceki adÄ±mdaki Ã§Ä±ktÄ±ya gÃ¶re dallanabilir.\n",
    "\n",
    "**KullanÄ±m Senaryosu:**\n",
    "\n",
    "Ã–rneÄŸin bir Ã¶ÄŸrenci danÄ±ÅŸman asistanÄ± geliÅŸtiriyorsak:\n",
    "\n",
    "KullanÄ±cÄ± PDF yÃ¼klediyse â†’ Ã¶zetleme dÃ¼ÄŸÃ¼mÃ¼ne git â†’ Ã¶zetle\n",
    "\n",
    "KullanÄ±cÄ± bir soru sorduysa â†’ RAG sorgu dÃ¼ÄŸÃ¼mÃ¼ne git â†’ cevabÄ± getir\n",
    "\n",
    "KullanÄ±cÄ± not ortalamasÄ± sorarsa â†’ tool Ã§aÄŸÄ±rma dÃ¼ÄŸÃ¼mÃ¼ne git\n",
    "\n",
    "LangGraph bu geÃ§iÅŸleri mantÄ±ksal bir grafik (dÃ¼ÄŸÃ¼mler ve kenarlar) Ã¼zerinden tanÄ±mlar. Bu da Ã¶zellikle Ã§ok adÄ±mlÄ± ve karar temelli yapay zeka sistemlerinde LangChainâ€™i Ã§ok daha gÃ¼Ã§lÃ¼ hale getirir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86604d39",
   "metadata": {
    "id": "86604d39"
   },
   "source": [
    "## Agent\n",
    "\n",
    "Agent sistemi, bÃ¼yÃ¼k dil modelinin (LLM) bir kullanÄ±cÄ±dan gelen komutu anlayarak hangi aracÄ± (Tool) Ã§alÄ±ÅŸtÄ±rmasÄ± gerektiÄŸine kendiliÄŸinden karar verdiÄŸi akÄ±llÄ± bir yapÄ±dÄ±r. LLM bu sÃ¼reÃ§te doÄŸal dili analiz eder, niyeti belirler ve ilgili iÅŸlemi otomatik olarak tetikler.\n",
    "\n",
    "Ã–rnek Senaryo:\n",
    "\n",
    "KullanÄ±cÄ±: \"BugÃ¼nkÃ¼ dÃ¶viz kuru?\"\n",
    "\n",
    "Agent: \"Bu bilgi iÃ§in doviz_kur_getir adlÄ± aracÄ± kullanmam gerekiyor\" â†’ Tool'u Ã§aÄŸÄ±rÄ±r ve sonucu kullanÄ±cÄ±ya sunar.\n",
    "\n",
    "LangChain frameworkâ€™Ã¼ iÃ§erisinde bu yapÄ± initialize_agent() fonksiyonu ile baÅŸlatÄ±lÄ±r. Toolâ€™lara aÃ§Ä±klayÄ±cÄ± gÃ¶rev tanÄ±mlarÄ± verilir, bÃ¶ylece model hangi aracÄ± ne zaman ve nasÄ±l kullanacaÄŸÄ±nÄ± anlayabilir.\n",
    "\n",
    "Agent sistemleri, Ã¶zellikle birden fazla veri kaynaÄŸÄ±na ya da iÅŸlem tÃ¼rÃ¼ne sahip uygulamalarda esnek ve akÄ±llÄ± Ã§Ã¶zÃ¼m saÄŸlar.\n",
    "\n",
    "LangChain Ã¶rneÄŸi:\n",
    "```python\n",
    "agent.run(\"BugÃ¼n hava nasÄ±l?\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b639f",
   "metadata": {
    "id": "4c8b639f"
   },
   "source": [
    "## Tool Calling\n",
    "\n",
    "Tool Calling, bir LLM'nin tanÄ±mlanmÄ±ÅŸ fonksiyonlarÄ± otomatik ÅŸekilde Ã§aÄŸÄ±rmasÄ±nÄ± saÄŸlar.\n",
    "\n",
    "OpenAI'de function_call, Anthropic'te tool_use olarak adlandÄ±rÄ±lÄ±r.\n",
    "\n",
    "\n",
    "BÃ¶ylece modelin bilgisi API'den Ã§ekilen verilerle desteklenir.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"tool\": \"get_weather\",\n",
    "  \"args\": { \"city\": \"Istanbul\" }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e6f79",
   "metadata": {
    "id": "9e6e6f79"
   },
   "source": [
    "## ğŸ“š Kaynaklar\n",
    "\n",
    "- https://www.youtube.com/watch?v=aZijAwhLjgQ\n",
    "- https://medium.com/%40mariaaawaheed/mastering-tools-and-tool-calling-agents-in-langchain-a-comprehensive-guide-18a566f2aac5\n",
    "- https://www.youtube.com/watch?v=HoonGqt7XpM\n",
    "- https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api\n",
    "- https://arxiv.org/abs/2005.11401\n",
    "- https://platform.openai.com/docs/guides/prompt-engineering\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
