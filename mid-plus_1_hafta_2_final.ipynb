{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f76fc7b",
   "metadata": {},
   "source": [
    "## Bölüm 0: Kurulum ve Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current Device: {device}\")\n",
    "print(f\"CPU Count: {torch.get_num_threads()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806951bc",
   "metadata": {},
   "source": [
    "Soru 1: Neural Network yapmak için hangi kütüphaneler lazım?\n",
    "\n",
    "Cevap:\n",
    "- torch: PyTorch'un ana modülü\n",
    "- torch.nn: Layer, activation fonksiyonları vs.\n",
    "- torch.optim: Optimizer'lar\n",
    "- numpy: Sayısal işlemler\n",
    "- matplotlib: Grafik çizimi\n",
    "\n",
    "Soru 2: GPU'da mı CPU'da mı çalıştırırız?\n",
    "\n",
    "Cevap:\n",
    "- İlk torch.cuda.is_available() ile GPU var mı kontrol et\n",
    "- device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "- Model ve veriyi .to(device) ile gönder\n",
    "- GPU'da çalışırsa çok daha hızlı"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634ff8b",
   "metadata": {},
   "source": [
    "## Bölüm 1: PyTorch Temelleri ve Basit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f42924",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "X = torch.randn(100, 5, device=device)\n",
    "y = torch.randn(100, 1, device=device)\n",
    "\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ee33e",
   "metadata": {},
   "source": [
    "Soru 1: Rastgele veri nasıl oluşturuyoruz?\n",
    "\n",
    "Cevap:\n",
    "- torch.randn() ile random sayılar\n",
    "- X = torch.randn(100, 5) → 100 örnek, 5 feature\n",
    "- y = torch.randn(100, 1) → target değişken\n",
    "- .to(device) ile GPU'ya gönder\n",
    "\n",
    "Soru 2: Model nasıl yazarız?\n",
    "\n",
    "Cevap:\n",
    "- nn.Module extend et\n",
    "- __init__ de layer'ları tanımla\n",
    "- forward() de veri flow'unu yaz\n",
    "- x → layer1 → relu → layer2 → output\n",
    "\n",
    "Soru 3: Eğitim döngüsü nasıl?\n",
    "\n",
    "Cevap:\n",
    "1. Forward: tahmin = model(X)\n",
    "2. Loss: hata = loss_fn(tahmin, y)\n",
    "3. Gradients temizle: optimizer.zero_grad()\n",
    "4. Backward: hata.backward()\n",
    "5. Güncelle: optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c75dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=10, output_size=1):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN(input_size=5, hidden_size=10, output_size=1).to(device)\n",
    "print(\"Model:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 50\n",
    "losses = []\n",
    "\n",
    "print(\"Training the model...\")\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, linewidth=2)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6cf29",
   "metadata": {},
   "source": [
    "## Bölüm 2: Yapay Sinir Ağı - XOR Problemi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baff39b",
   "metadata": {},
   "source": [
    "Soru 1: XOR problemi nedir?\n",
    "\n",
    "Cevap:\n",
    "- XOR lineer değil, tek layer'la çözemezsin\n",
    "- Hidden layer eklersin non-linear hale gelir\n",
    "- Input(2) → Hidden(4) → Output(1)\n",
    "- ReLU ve Sigmoid kullanırsın\n",
    "\n",
    "Soru 2: Matematiksel işlemler nasıl?\n",
    "\n",
    "Cevap:\n",
    "- Her layer: z = W×x + b\n",
    "- Activation: ReLU(z)\n",
    "- Tersine: chain rule ile gradient\n",
    "- Her layer'dan gradient geri gidiyor\n",
    "\n",
    "Soru 3: Gradient nedir?\n",
    "\n",
    "Cevap:\n",
    "- Gradient = loss'un ağırlığa göre değişim\n",
    "- Nereye gidersek loss azalır bunu gösteriyor\n",
    "- w = w - learning_rate × gradient\n",
    "- Bunu yapmasak ağ öğrenemezdi\n",
    "\n",
    "Soru 4: Overfitting, epoch, veri split?\n",
    "\n",
    "Cevap:\n",
    "- Overfitting: ağ eğitim verisine çok alışıyor\n",
    "- Training loss azalır, test loss yükselir\n",
    "- Epoch: tüm veriyi bir kez geçirmek\n",
    "- Veriyi train/test'e böl, overfitting kontrol et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xor = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32, device=device)\n",
    "y_xor = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32, device=device)\n",
    "\n",
    "print(\"XOR Dataset:\")\n",
    "print(f\"Inputs:\\n{X_xor}\")\n",
    "print(f\"Targets:\\n{y_xor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XOR_NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "xor_model = XOR_NN().to(device)\n",
    "xor_optimizer = optim.Adam(xor_model.parameters(), lr=0.01)\n",
    "xor_loss_fn = nn.BCELoss()\n",
    "\n",
    "xor_losses = []\n",
    "xor_epochs = 1000\n",
    "\n",
    "print(\"Training XOR model...\")\n",
    "for epoch in range(xor_epochs):\n",
    "    y_pred = xor_model(X_xor)\n",
    "    loss = xor_loss_fn(y_pred, y_xor)\n",
    "    xor_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    xor_optimizer.step()\n",
    "    \n",
    "    xor_losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{xor_epochs}], Loss: {loss.item():.6f}\")\n",
    "\n",
    "print(\"\\nXOR Model Predictions:\")\n",
    "with torch.no_grad():\n",
    "    predictions = xor_model(X_xor)\n",
    "    for i in range(len(X_xor)):\n",
    "        print(f\"Input: {X_xor[i].cpu().numpy()} → Predicted: {predictions[i].item():.4f}, Target: {y_xor[i].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c80c0",
   "metadata": {},
   "source": [
    "## Bölüm 3: Matematiksel Tanımlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993d62d",
   "metadata": {},
   "source": [
    "Soru 1: Activation function'lar?\n",
    "\n",
    "Cevap:\n",
    "- ReLU: En çok kullanılan, hızlı, hidden layer'lar için\n",
    "- Sigmoid: 0-1 arasında, binary classification output\n",
    "- Tanh: -1 ile 1 arasında, sigmoid'den iyi\n",
    "- Leaky ReLU: ReLU'nun ölü nöron problemi çözüyor\n",
    "- Softmax: Multi-class classification\n",
    "\n",
    "Soru 2: Loss function'lar?\n",
    "\n",
    "Cevap:\n",
    "- MSE: Regression, tahmin ve gerçek farkının karesi\n",
    "- Cross Entropy: Classification, ne kadar yanlış\n",
    "- Binary Cross Entropy: 2 sınıflı problemler\n",
    "- L1 Loss: Regression, aykırı değerlere dayanıklı\n",
    "\n",
    "Soru 3: Gradient descent nasıl?\n",
    "\n",
    "Cevap:\n",
    "- Gradient hesapla\n",
    "- w = w - learning_rate × gradient\n",
    "- Tekrar tekrar\n",
    "- Loss azalana kadar\n",
    "\n",
    "Soru 4: NN'nin matematiksel temeli?\n",
    "\n",
    "Cevap:\n",
    "- Linear Algebra: Matrisler, vektörler\n",
    "- Calculus: Türev, chain rule\n",
    "- Probability: Softmax, olasılıklar\n",
    "- Optimization: Gradient descent, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bffa1a",
   "metadata": {},
   "source": [
    "## Bölüm 4: Veri Akışı ve Yaklaşımlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaedabb6",
   "metadata": {},
   "source": [
    "Soru 1: Bir problem nasıl çözeriz NN ile?\n",
    "\n",
    "Cevap:\n",
    "1. Problemi anla\n",
    "2. Veriyi hazırla\n",
    "3. Model tasarla\n",
    "4. Activation ve loss seç\n",
    "5. Optimizer aç\n",
    "6. Eğit\n",
    "7. Sonucu kontrol et\n",
    "\n",
    "Soru 2: Veri ağda nasıl akar?\n",
    "\n",
    "Cevap:\n",
    "- Input layer\n",
    "- Hidden layers: Veri dönüştürülüyor\n",
    "- Output layer: Sonuç\n",
    "- Tersine: Loss'tan başlayıp gradient gidiyor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f11a0",
   "metadata": {},
   "source": [
    "## Bölüm 5: Değerlendirme ve Görevler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8b129",
   "metadata": {},
   "source": [
    "Soru: PyTorch ve NN projesi yap\n",
    "\n",
    "Cevap:\n",
    "\n",
    "Fashion MNIST ile sınıflandırma ağı yaptık.\n",
    "\n",
    "Model yapısı:\n",
    "- Input: 784 nöron (28×28 görüntü)\n",
    "- Hidden 1: 256 nöron + ReLU + Dropout\n",
    "- Hidden 2: 128 nöron + ReLU + Dropout  \n",
    "- Hidden 3: 64 nöron + ReLU + Dropout\n",
    "- Output: 10 nöron (10 sınıf)\n",
    "\n",
    "Eğitim:\n",
    "- Adam optimizer\n",
    "- CrossEntropyLoss\n",
    "- 15 epoch\n",
    "- Batch size 64\n",
    "\n",
    "Sonuçlar:\n",
    "- Loss grafikleri\n",
    "- Accuracy grafikleri\n",
    "- Confusion matrix\n",
    "- Detaylı rapor\n",
    "\n",
    "Proje tamamlandı."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
